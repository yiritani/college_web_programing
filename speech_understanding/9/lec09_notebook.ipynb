{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a424b44",
   "metadata": {},
   "source": [
    "# Speech Understanding \n",
    "# Lecture 9: The SpeechRecognition Module\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3983e7c",
   "metadata": {},
   "source": [
    "### Mark Hasegawa-Johnson, KCGI, December 17, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa13a99",
   "metadata": {},
   "source": [
    "In today's lecture, we will learn how to use the <a href=\"https://pypi.org/project/SpeechRecognition/\">Speech Recognition</a> module in order to access high-performance commercial and open-source speech recognizers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8ca0a6",
   "metadata": {},
   "source": [
    "Here are the contents:\n",
    "1. <a href=\"#section_1\">Installing SpeechRecognition</a>\n",
    "1. <a href=\"#section_2\">Using speech_recognition from the microphone</a>\n",
    "1. <a href=\"#section_3\">Using speech_recognition to perform a web search</a>\n",
    "1. <a href=\"#section_4\">Using speech_recognition from an audio file</a>\n",
    "1. <a href=\"#homework\">Homework</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f5b87c",
   "metadata": {},
   "source": [
    "<a id='section_1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc1f1a1",
   "metadata": {},
   "source": [
    "## 1. Installing SpeechRecognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c958c9dc",
   "metadata": {},
   "source": [
    "The SpeechRecognition module is installed using pip and conda.  If you have anaconda installed, you can try the following two commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anyio==3.6.2\r\n",
      "appdirs==1.4.4\r\n",
      "appnope==0.1.3\r\n",
      "argon2-cffi==21.3.0\r\n",
      "argon2-cffi-bindings==21.2.0\r\n",
      "asttokens==2.0.8\r\n",
      "attrs==22.1.0\r\n",
      "audioread==3.0.0\r\n",
      "backcall==0.2.0\r\n",
      "beautifulsoup4==4.11.1\r\n",
      "bleach==5.0.1\r\n",
      "certifi==2022.9.24\r\n",
      "cffi==1.15.1\r\n",
      "charset-normalizer==2.1.1\r\n",
      "contourpy==1.0.5\r\n",
      "cycler==0.11.0\r\n",
      "debugpy==1.6.3\r\n",
      "decorator==5.1.1\r\n",
      "defusedxml==0.7.1\r\n",
      "entrypoints==0.4\r\n",
      "executing==1.1.1\r\n",
      "fastjsonschema==2.16.2\r\n",
      "fonttools==4.38.0\r\n",
      "idna==3.4\r\n",
      "importlib-metadata==5.0.0\r\n",
      "ipykernel==6.16.2\r\n",
      "ipython==8.5.0\r\n",
      "ipython-genutils==0.2.0\r\n",
      "ipywebrtc==0.6.0\r\n",
      "ipywidgets==8.0.2\r\n",
      "jedi==0.18.1\r\n",
      "Jinja2==3.1.2\r\n",
      "joblib==1.2.0\r\n",
      "jsonschema==4.16.0\r\n",
      "jupyter==1.0.0\r\n",
      "jupyter-console==6.4.4\r\n",
      "jupyter-server==1.21.0\r\n",
      "jupyter_client==7.4.4\r\n",
      "jupyter_core==4.11.2\r\n",
      "jupyterlab-pygments==0.2.2\r\n",
      "jupyterlab-widgets==3.0.3\r\n",
      "kiwisolver==1.4.4\r\n",
      "librosa==0.9.2\r\n",
      "llvmlite==0.39.1\r\n",
      "MarkupSafe==2.1.1\r\n",
      "matplotlib==3.6.1\r\n",
      "matplotlib-inline==0.1.6\r\n",
      "mistune==2.0.4\r\n",
      "nbclassic==0.4.5\r\n",
      "nbclient==0.7.0\r\n",
      "nbconvert==7.2.3\r\n",
      "nbformat==5.7.0\r\n",
      "nest-asyncio==1.5.6\r\n",
      "notebook==6.5.1\r\n",
      "notebook_shim==0.2.0\r\n",
      "numba==0.56.4\r\n",
      "numpy==1.23.4\r\n",
      "packaging==21.3\r\n",
      "pandocfilters==1.5.0\r\n",
      "parso==0.8.3\r\n",
      "pexpect==4.8.0\r\n",
      "pickleshare==0.7.5\r\n",
      "Pillow==9.2.0\r\n",
      "pooch==1.6.0\r\n",
      "prometheus-client==0.15.0\r\n",
      "prompt-toolkit==3.0.31\r\n",
      "psutil==5.9.3\r\n",
      "ptyprocess==0.7.0\r\n",
      "pure-eval==0.2.2\r\n",
      "PyAudio==0.2.12\r\n",
      "pycparser==2.21\r\n",
      "Pygments==2.13.0\r\n",
      "pyparsing==3.0.9\r\n",
      "pyrsistent==0.18.1\r\n",
      "python-dateutil==2.8.2\r\n",
      "pyzmq==24.0.1\r\n",
      "qtconsole==5.3.2\r\n",
      "QtPy==2.2.1\r\n",
      "requests==2.28.1\r\n",
      "resampy==0.4.2\r\n",
      "scikit-learn==1.1.3\r\n",
      "scipy==1.9.3\r\n",
      "Send2Trash==1.8.0\r\n",
      "six==1.16.0\r\n",
      "sniffio==1.3.0\r\n",
      "soundfile==0.11.0\r\n",
      "soupsieve==2.3.2.post1\r\n",
      "SpeechRecognition==3.9.0\r\n",
      "stack-data==0.5.1\r\n",
      "terminado==0.17.0\r\n",
      "threadpoolctl==3.1.0\r\n",
      "tinycss2==1.2.1\r\n",
      "tornado==6.2\r\n",
      "traitlets==5.5.0\r\n",
      "urllib3==1.26.12\r\n",
      "wcwidth==0.2.5\r\n",
      "webencodings==0.5.1\r\n",
      "websocket-client==1.4.1\r\n",
      "widgetsnbextension==4.0.3\r\n",
      "zipp==3.10.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip freeze"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0c7fd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting SpeechRecognition\r\n",
      "  Downloading SpeechRecognition-3.9.0-py2.py3-none-any.whl (32.8 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m32.8/32.8 MB\u001B[0m \u001B[31m10.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: requests>=2.26.0 in /Users/yuuiri/PycharmProjects/college/speech_understanding/venv/lib/python3.9/site-packages (from SpeechRecognition) (2.28.1)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/yuuiri/PycharmProjects/college/speech_understanding/venv/lib/python3.9/site-packages (from requests>=2.26.0->SpeechRecognition) (2.1.1)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/yuuiri/PycharmProjects/college/speech_understanding/venv/lib/python3.9/site-packages (from requests>=2.26.0->SpeechRecognition) (1.26.12)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/yuuiri/PycharmProjects/college/speech_understanding/venv/lib/python3.9/site-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yuuiri/PycharmProjects/college/speech_understanding/venv/lib/python3.9/site-packages (from requests>=2.26.0->SpeechRecognition) (2022.9.24)\r\n",
      "Installing collected packages: SpeechRecognition\r\n",
      "Successfully installed SpeechRecognition-3.9.0\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m22.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edfa8e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\r\n",
      "Solving environment: done\r\n",
      "\r\n",
      "## Package Plan ##\r\n",
      "\r\n",
      "  environment location: /Users/yuuiri/opt/anaconda3\r\n",
      "\r\n",
      "  added / updated specs:\r\n",
      "    - pyaudio\r\n",
      "\r\n",
      "\r\n",
      "The following packages will be downloaded:\r\n",
      "\r\n",
      "    package                    |            build\r\n",
      "    ---------------------------|-----------------\r\n",
      "    conda-22.11.1              |   py39hecd8cb5_4         941 KB\r\n",
      "    portaudio-19.6.0           |       h647c56a_4          75 KB\r\n",
      "    pyaudio-0.2.11             |   py39h9ed2024_2          31 KB\r\n",
      "    ruamel.yaml-0.17.21        |   py39hca72f7f_0         179 KB\r\n",
      "    ruamel.yaml.clib-0.2.6     |   py39hca72f7f_1         126 KB\r\n",
      "    ------------------------------------------------------------\r\n",
      "                                           Total:         1.3 MB\r\n",
      "\r\n",
      "The following NEW packages will be INSTALLED:\r\n",
      "\r\n",
      "  portaudio          pkgs/main/osx-64::portaudio-19.6.0-h647c56a_4 None\r\n",
      "  pyaudio            pkgs/main/osx-64::pyaudio-0.2.11-py39h9ed2024_2 None\r\n",
      "  ruamel.yaml        pkgs/main/osx-64::ruamel.yaml-0.17.21-py39hca72f7f_0 None\r\n",
      "  ruamel.yaml.clib   pkgs/main/osx-64::ruamel.yaml.clib-0.2.6-py39hca72f7f_1 None\r\n",
      "\r\n",
      "The following packages will be UPDATED:\r\n",
      "\r\n",
      "  conda                               22.9.0-py39hecd8cb5_0 --> 22.11.1-py39hecd8cb5_4 None\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Downloading and Extracting Packages\r\n",
      "ruamel.yaml.clib-0.2 | 126 KB    | ##################################### | 100% \r\n",
      "conda-22.11.1        | 941 KB    | ##################################### | 100% \r\n",
      "ruamel.yaml-0.17.21  | 179 KB    | ##################################### | 100% \r\n",
      "portaudio-19.6.0     | 75 KB     | ##################################### | 100% \r\n",
      "pyaudio-0.2.11       | 31 KB     | ##################################### | 100% \r\n",
      "Preparing transaction: done\r\n",
      "Verifying transaction: done\r\n",
      "Executing transaction: done\r\n",
      "Retrieving notices: ...working... done\r\n"
     ]
    }
   ],
   "source": [
    "!conda install pyaudio -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ea66e9",
   "metadata": {},
   "source": [
    "The SpeechRecognition package is a python user interface that connects, in the back end, to many different speech recognizers, see: https://pypi.org/project/SpeechRecognition/\n",
    "\n",
    "To start with, let's use the Google speech recognizer.  This one only works if you're connected to the internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "487e353d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python is listening...\n",
      "Could not import the PyAudio C module '_portaudio'.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Could not find PyAudio; check installation",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "File \u001B[0;32m~/PycharmProjects/college/speech_understanding/venv/lib/python3.9/site-packages/speech_recognition/__init__.py:120\u001B[0m, in \u001B[0;36mMicrophone.get_pyaudio\u001B[0;34m()\u001B[0m\n\u001B[1;32m    119\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 120\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpyaudio\u001B[39;00m\n\u001B[1;32m    121\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n",
      "File \u001B[0;32m~/PycharmProjects/college/speech_understanding/venv/lib/python3.9/site-packages/pyaudio.py:116\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 116\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01m_portaudio\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpa\u001B[39;00m\n\u001B[1;32m    117\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n",
      "\u001B[0;31mImportError\u001B[0m: dlopen(/Users/yuuiri/PycharmProjects/college/speech_understanding/venv/lib/python3.9/site-packages/_portaudio.cpython-39-darwin.so, 0x0002): symbol not found in flat namespace (_PaMacCore_SetupChannelMap)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [9], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m speech \u001B[38;5;241m=\u001B[39m sr\u001B[38;5;241m.\u001B[39mRecognizer()\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPython is listening...\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 4\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43msr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mMicrophone\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m source:\n\u001B[1;32m      5\u001B[0m     speech\u001B[38;5;241m.\u001B[39madjust_for_ambient_noise(source)\n\u001B[1;32m      6\u001B[0m     audio \u001B[38;5;241m=\u001B[39m speech\u001B[38;5;241m.\u001B[39mlisten(source)\n",
      "File \u001B[0;32m~/PycharmProjects/college/speech_understanding/venv/lib/python3.9/site-packages/speech_recognition/__init__.py:92\u001B[0m, in \u001B[0;36mMicrophone.__init__\u001B[0;34m(self, device_index, sample_rate, chunk_size)\u001B[0m\n\u001B[1;32m     89\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(chunk_size, \u001B[38;5;28mint\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m chunk_size \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mChunk size must be a positive integer\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     91\u001B[0m \u001B[38;5;66;03m# set up PyAudio\u001B[39;00m\n\u001B[0;32m---> 92\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpyaudio_module \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_pyaudio\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     93\u001B[0m audio \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpyaudio_module\u001B[38;5;241m.\u001B[39mPyAudio()\n\u001B[1;32m     94\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/PycharmProjects/college/speech_understanding/venv/lib/python3.9/site-packages/speech_recognition/__init__.py:122\u001B[0m, in \u001B[0;36mMicrophone.get_pyaudio\u001B[0;34m()\u001B[0m\n\u001B[1;32m    120\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpyaudio\u001B[39;00m\n\u001B[1;32m    121\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n\u001B[0;32m--> 122\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCould not find PyAudio; check installation\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    123\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdistutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mversion\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m LooseVersion\n\u001B[1;32m    124\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m LooseVersion(pyaudio\u001B[38;5;241m.\u001B[39m__version__) \u001B[38;5;241m<\u001B[39m LooseVersion(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m0.2.11\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "\u001B[0;31mAttributeError\u001B[0m: Could not find PyAudio; check installation"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "speech = sr.Recognizer()\n",
    "print('Python is listening...')\n",
    "with sr.Microphone() as source:\n",
    "    speech.adjust_for_ambient_noise(source)\n",
    "    audio = speech.listen(source)\n",
    "    inp = speech.recognize_google(audio)\n",
    "    print('You just said',inp,'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731a115a",
   "metadata": {},
   "source": [
    "<a id='section_2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f8148f",
   "metadata": {},
   "source": [
    "## 2. Using SpeechRecognition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "500c2dc3",
   "metadata": {},
   "source": [
    "We can use python's <a href=\"https://docs.python.org/3/tutorial/errors.html\">exception handling</a> in case the speech recognizer has trouble recognizing what we say:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832e9140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "speech = sr.Recognizer()\n",
    "\n",
    "while True:\n",
    "    print('Python is listening...')\n",
    "    with sr.Microphone() as source:\n",
    "        speech.adjust_for_ambient_noise(source)\n",
    "        try:\n",
    "            audio = speech.listen(source)\n",
    "            inp = speech.recognize_google(audio)\n",
    "            print('You just said',inp,'.')\n",
    "        except sr.UnknownValueError:\n",
    "            continue\n",
    "        except sr.RequestError:\n",
    "            continue\n",
    "        except sr.WaitTimeoutError:\n",
    "            continue\n",
    "        if inp==\"stop listening\":\n",
    "            print('Goodbye!')\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf6953a",
   "metadata": {},
   "source": [
    "<a id='section_3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ea109e",
   "metadata": {},
   "source": [
    "## 3. Using SpeechRecognizer to search the web"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b91f8c",
   "metadata": {},
   "source": [
    "The speech recognizer can now be used to give text input for any application.  For example, let's try using it to search the web.  \n",
    "\n",
    "To start with, here's how we open a web page in python:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cf5dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "webbrowser.open(\"http://wsj.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1976ef0e",
   "metadata": {},
   "source": [
    "Now let's use the speech recognizer to input the web page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5183df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import webbrowser\n",
    "speech = sr.Recognizer()\n",
    "\n",
    "while True:\n",
    "    print('Python is listening...')\n",
    "    with sr.Microphone() as source:\n",
    "        speech.adjust_for_ambient_noise(source)\n",
    "        try:\n",
    "            audio = speech.listen(source)\n",
    "            inp = speech.recognize_google(audio)\n",
    "            print('You just said',inp,'.')\n",
    "            inp.replace('browser ', '')\n",
    "            webbrowser.open(\"http://\" + inp)\n",
    "        except sr.UnknownValueError:\n",
    "            continue\n",
    "        except sr.RequestError:\n",
    "            continue\n",
    "        except sr.WaitTimeoutError:\n",
    "            continue\n",
    "        if inp==\"stop listening\":\n",
    "            print('Goodbye!')\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84551323",
   "metadata": {},
   "source": [
    "Finally, let's use speech recognition to perform a web search.  To do that, all we need is to replace this line:\n",
    "\n",
    "```webbrowser.open(\"http://\" + inp)```\n",
    "\n",
    "...with this one:\n",
    "\n",
    "```webbrowser.open(\"http://google.com/search?q=\" + inp)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e103da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import webbrowser\n",
    "speech = sr.Recognizer()\n",
    "\n",
    "while True:\n",
    "    print('Python is listening...')\n",
    "    with sr.Microphone() as source:\n",
    "        speech.adjust_for_ambient_noise(source)\n",
    "        try:\n",
    "            audio = speech.listen(source)\n",
    "            inp = speech.recognize_google(audio)\n",
    "            print('You just said',inp,'.')\n",
    "            inp.replace('browser ', '')\n",
    "            webbrowser.open(\"http://google.com/search?q=\" + inp)\n",
    "        except sr.UnknownValueError:\n",
    "            continue\n",
    "        except sr.RequestError:\n",
    "            continue\n",
    "        except sr.WaitTimeoutError:\n",
    "            continue\n",
    "        if inp==\"stop listening\":\n",
    "            print('Goodbye!')\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba21aaa8",
   "metadata": {},
   "source": [
    "<a id=\"section_4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa81c535",
   "metadata": {},
   "source": [
    "## 4. Using speech_recognition from an audio file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d3c108",
   "metadata": {},
   "source": [
    "If you have an audio file, you can use the speech_recognition module to transcribe it.  For example, let's download the audio file we used in lecture 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5b6544",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, soundfile, IPython\n",
    "\n",
    "example_url = \"https://catalog.ldc.upenn.edu/desc/addenda/LDC93S1.wav\"\n",
    "webdata = urllib.request.urlopen(example_url).read()\n",
    "with open(\"webdata.wav\", \"wb\") as f:\n",
    "    f.write(webdata)\n",
    "    \n",
    "speech_wave, speech_rate = soundfile.read(\"webdata.wav\")\n",
    "IPython.display.Audio(data=speech_wave, rate=speech_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3069f3e",
   "metadata": {},
   "source": [
    "Now let's use speech_recognition to transcribe it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bc3623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "speech = sr.Recognizer()\n",
    "with sr.AudioFile(\"webdata.wav\") as source:\n",
    "    audio = speech.record(source)\n",
    "    inp = speech.recognize_google(audio)\n",
    "    print('The person in this audio file said:',inp,'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564707ab",
   "metadata": {},
   "source": [
    "<a id='homework'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6b32d4",
   "metadata": {},
   "source": [
    "## Homework for Week 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9eeaa5",
   "metadata": {},
   "source": [
    "Create a text file called `week9.py`.\n",
    "\n",
    "This file should `def` a function called `transcribe_wavefile`, with the following parameters:\n",
    "* Input: str = name of the input file\n",
    "* Return: str = recognized text  \n",
    "\n",
    "Here is a template that you can cut and paste, to get started:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c8138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "def transcribe_wavefile(filename):\n",
    "    '''\n",
    "    Use sr.Recognizer.AudioFile(filename) as the source,\n",
    "    recognize from that source,\n",
    "    and return the recognized text.\n",
    "    '''\n",
    "    raise \"You need to write this part!\"\n",
    "    return inp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9fb7cc",
   "metadata": {},
   "source": [
    "Test whether your code works by running the following block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab6ecae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import week9, importlib\n",
    "importlib.reload(week9)\n",
    "\n",
    "inp = week9.transcribe_wavefile(\"webdata.wav\")\n",
    "print(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c769003c",
   "metadata": {},
   "source": [
    "When the block above is working, try uploading your text file `week9.py` to <a href=\"https://www.gradescope.com/\">Gradescope</a>.  The autograder checks the following things:\n",
    "\n",
    "1. Did you submit a text file called `week9.py`?\n",
    "1. Does your text file contains a method called `transcribe_wavefile`?\n",
    "1. Does `week9.transcribe_wavefile` return a string?\n",
    "1. Does `week9.transcribe_wavefile(\"webdata.wav\")` return the string `she has a duck suit and Gracie washer all year`?\n",
    "1. Does `week9.transcribe_wavefile` also work if applied to a secret audio file that is different from `webdata.wav`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ad19aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
