{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a424b44",
   "metadata": {},
   "source": [
    "# Speech Understanding \n",
    "# Lecture 9: The SpeechRecognition Module\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3983e7c",
   "metadata": {},
   "source": [
    "### Mark Hasegawa-Johnson, KCGI, December 17, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa13a99",
   "metadata": {},
   "source": [
    "In today's lecture, we will learn how to use the <a href=\"https://pypi.org/project/SpeechRecognition/\">Speech Recognition</a> module in order to access high-performance commercial and open-source speech recognizers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8ca0a6",
   "metadata": {},
   "source": [
    "Here are the contents:\n",
    "1. <a href=\"#section_1\">Installing SpeechRecognition</a>\n",
    "1. <a href=\"#section_2\">Using speech_recognition from the microphone</a>\n",
    "1. <a href=\"#section_3\">Using speech_recognition to perform a web search</a>\n",
    "1. <a href=\"#section_4\">Using speech_recognition from an audio file</a>\n",
    "1. <a href=\"#homework\">Homework</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f5b87c",
   "metadata": {},
   "source": [
    "<a id='section_1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc1f1a1",
   "metadata": {},
   "source": [
    "## 1. Installing SpeechRecognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c958c9dc",
   "metadata": {},
   "source": [
    "The SpeechRecognition module is installed using pip and conda.  If you have anaconda installed, you can try the following two commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anyio==3.6.2\r\n",
      "appdirs==1.4.4\r\n",
      "appnope==0.1.3\r\n",
      "argon2-cffi==21.3.0\r\n",
      "argon2-cffi-bindings==21.2.0\r\n",
      "asttokens==2.0.8\r\n",
      "attrs==22.1.0\r\n",
      "audioread==3.0.0\r\n",
      "backcall==0.2.0\r\n",
      "beautifulsoup4==4.11.1\r\n",
      "bleach==5.0.1\r\n",
      "certifi==2022.9.24\r\n",
      "cffi==1.15.1\r\n",
      "charset-normalizer==2.1.1\r\n",
      "contourpy==1.0.5\r\n",
      "cycler==0.11.0\r\n",
      "debugpy==1.6.3\r\n",
      "decorator==5.1.1\r\n",
      "defusedxml==0.7.1\r\n",
      "entrypoints==0.4\r\n",
      "executing==1.1.1\r\n",
      "fastjsonschema==2.16.2\r\n",
      "fonttools==4.38.0\r\n",
      "idna==3.4\r\n",
      "importlib-metadata==5.0.0\r\n",
      "ipykernel==6.16.2\r\n",
      "ipython==8.5.0\r\n",
      "ipython-genutils==0.2.0\r\n",
      "ipywebrtc==0.6.0\r\n",
      "ipywidgets==8.0.2\r\n",
      "jedi==0.18.1\r\n",
      "Jinja2==3.1.2\r\n",
      "joblib==1.2.0\r\n",
      "jsonschema==4.16.0\r\n",
      "jupyter==1.0.0\r\n",
      "jupyter-console==6.4.4\r\n",
      "jupyter-server==1.21.0\r\n",
      "jupyter_client==7.4.4\r\n",
      "jupyter_core==4.11.2\r\n",
      "jupyterlab-pygments==0.2.2\r\n",
      "jupyterlab-widgets==3.0.3\r\n",
      "kiwisolver==1.4.4\r\n",
      "librosa==0.9.2\r\n",
      "llvmlite==0.39.1\r\n",
      "MarkupSafe==2.1.1\r\n",
      "matplotlib==3.6.1\r\n",
      "matplotlib-inline==0.1.6\r\n",
      "mistune==2.0.4\r\n",
      "nbclassic==0.4.5\r\n",
      "nbclient==0.7.0\r\n",
      "nbconvert==7.2.3\r\n",
      "nbformat==5.7.0\r\n",
      "nest-asyncio==1.5.6\r\n",
      "notebook==6.5.1\r\n",
      "notebook_shim==0.2.0\r\n",
      "numba==0.56.4\r\n",
      "numpy==1.23.4\r\n",
      "packaging==21.3\r\n",
      "pandocfilters==1.5.0\r\n",
      "parso==0.8.3\r\n",
      "pexpect==4.8.0\r\n",
      "pickleshare==0.7.5\r\n",
      "Pillow==9.2.0\r\n",
      "pooch==1.6.0\r\n",
      "prometheus-client==0.15.0\r\n",
      "prompt-toolkit==3.0.31\r\n",
      "psutil==5.9.3\r\n",
      "ptyprocess==0.7.0\r\n",
      "pure-eval==0.2.2\r\n",
      "PyAudio==0.2.12\r\n",
      "pycparser==2.21\r\n",
      "Pygments==2.13.0\r\n",
      "pyparsing==3.0.9\r\n",
      "pyrsistent==0.18.1\r\n",
      "python-dateutil==2.8.2\r\n",
      "pyzmq==24.0.1\r\n",
      "qtconsole==5.3.2\r\n",
      "QtPy==2.2.1\r\n",
      "requests==2.28.1\r\n",
      "resampy==0.4.2\r\n",
      "scikit-learn==1.1.3\r\n",
      "scipy==1.9.3\r\n",
      "Send2Trash==1.8.0\r\n",
      "six==1.16.0\r\n",
      "sniffio==1.3.0\r\n",
      "soundfile==0.11.0\r\n",
      "soupsieve==2.3.2.post1\r\n",
      "SpeechRecognition==3.9.0\r\n",
      "stack-data==0.5.1\r\n",
      "terminado==0.17.0\r\n",
      "threadpoolctl==3.1.0\r\n",
      "tinycss2==1.2.1\r\n",
      "tornado==6.2\r\n",
      "traitlets==5.5.0\r\n",
      "urllib3==1.26.12\r\n",
      "wcwidth==0.2.5\r\n",
      "webencodings==0.5.1\r\n",
      "websocket-client==1.4.1\r\n",
      "widgetsnbextension==4.0.3\r\n",
      "zipp==3.10.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip freeze"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0c7fd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting SpeechRecognition\r\n",
      "  Downloading SpeechRecognition-3.9.0-py2.py3-none-any.whl (32.8 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m32.8/32.8 MB\u001B[0m \u001B[31m10.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: requests>=2.26.0 in /Users/yuuiri/PycharmProjects/college/speech_understanding/venv/lib/python3.9/site-packages (from SpeechRecognition) (2.28.1)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/yuuiri/PycharmProjects/college/speech_understanding/venv/lib/python3.9/site-packages (from requests>=2.26.0->SpeechRecognition) (2.1.1)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/yuuiri/PycharmProjects/college/speech_understanding/venv/lib/python3.9/site-packages (from requests>=2.26.0->SpeechRecognition) (1.26.12)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/yuuiri/PycharmProjects/college/speech_understanding/venv/lib/python3.9/site-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yuuiri/PycharmProjects/college/speech_understanding/venv/lib/python3.9/site-packages (from requests>=2.26.0->SpeechRecognition) (2022.9.24)\r\n",
      "Installing collected packages: SpeechRecognition\r\n",
      "Successfully installed SpeechRecognition-3.9.0\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m22.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edfa8e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyaudio\r\n",
      "  Using cached PyAudio-0.2.12.tar.gz (42 kB)\r\n",
      "  Installing build dependencies ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Getting requirements to build wheel ... \u001B[?25ldone\r\n",
      "\u001B[?25h    Preparing wheel metadata ... \u001B[?25ldone\r\n",
      "\u001B[?25hBuilding wheels for collected packages: pyaudio\r\n",
      "  Building wheel for pyaudio (PEP 517) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for pyaudio: filename=PyAudio-0.2.12-cp39-cp39-macosx_10_9_universal2.whl size=38250 sha256=c5c0f2cfb3ac0a658e0f4641a84b9b2641ad5ae85b52e8025529b8d55a296db6\r\n",
      "  Stored in directory: /Users/yuuiri/Library/Caches/pip/wheels/66/6c/95/76afa159d5be5215b6f6499625a0ddf1134e60f85beeba6e7a\r\n",
      "Successfully built pyaudio\r\n",
      "Installing collected packages: pyaudio\r\n",
      "Successfully installed pyaudio-0.2.12\r\n",
      "\u001B[33mWARNING: You are using pip version 21.1.2; however, version 22.3.1 is available.\r\n",
      "You should consider upgrading via the '/Users/yuuiri/PycharmProjects/college/venv/bin/python -m pip install --upgrade pip' command.\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pyaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ea66e9",
   "metadata": {},
   "source": [
    "The SpeechRecognition package is a python user interface that connects, in the back end, to many different speech recognizers, see: https://pypi.org/project/SpeechRecognition/\n",
    "\n",
    "To start with, let's use the Google speech recognizer.  This one only works if you're connected to the internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "487e353d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'speech_recognition'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[0;32mIn [2]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mspeech_recognition\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01msr\u001B[39;00m\n\u001B[1;32m      2\u001B[0m speech \u001B[38;5;241m=\u001B[39m sr\u001B[38;5;241m.\u001B[39mRecognizer()\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPython is listening...\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'speech_recognition'"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "speech = sr.Recognizer()\n",
    "print('Python is listening...')\n",
    "with sr.Microphone() as source:\n",
    "    speech.adjust_for_ambient_noise(source)\n",
    "    audio = speech.listen(source)\n",
    "    inp = speech.recognize_google(audio)\n",
    "    print('You just said',inp,'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731a115a",
   "metadata": {},
   "source": [
    "<a id='section_2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f8148f",
   "metadata": {},
   "source": [
    "## 2. Using SpeechRecognition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "500c2dc3",
   "metadata": {},
   "source": [
    "We can use python's <a href=\"https://docs.python.org/3/tutorial/errors.html\">exception handling</a> in case the speech recognizer has trouble recognizing what we say:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832e9140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "speech = sr.Recognizer()\n",
    "\n",
    "while True:\n",
    "    print('Python is listening...')\n",
    "    with sr.Microphone() as source:\n",
    "        speech.adjust_for_ambient_noise(source)\n",
    "        try:\n",
    "            audio = speech.listen(source)\n",
    "            inp = speech.recognize_google(audio)\n",
    "            print('You just said',inp,'.')\n",
    "        except sr.UnknownValueError:\n",
    "            continue\n",
    "        except sr.RequestError:\n",
    "            continue\n",
    "        except sr.WaitTimeoutError:\n",
    "            continue\n",
    "        if inp==\"stop listening\":\n",
    "            print('Goodbye!')\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf6953a",
   "metadata": {},
   "source": [
    "<a id='section_3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ea109e",
   "metadata": {},
   "source": [
    "## 3. Using SpeechRecognizer to search the web"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b91f8c",
   "metadata": {},
   "source": [
    "The speech recognizer can now be used to give text input for any application.  For example, let's try using it to search the web.  \n",
    "\n",
    "To start with, here's how we open a web page in python:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cf5dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "webbrowser.open(\"http://wsj.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1976ef0e",
   "metadata": {},
   "source": [
    "Now let's use the speech recognizer to input the web page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5183df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import webbrowser\n",
    "speech = sr.Recognizer()\n",
    "\n",
    "while True:\n",
    "    print('Python is listening...')\n",
    "    with sr.Microphone() as source:\n",
    "        speech.adjust_for_ambient_noise(source)\n",
    "        try:\n",
    "            audio = speech.listen(source)\n",
    "            inp = speech.recognize_google(audio)\n",
    "            print('You just said',inp,'.')\n",
    "            inp.replace('browser ', '')\n",
    "            webbrowser.open(\"http://\" + inp)\n",
    "        except sr.UnknownValueError:\n",
    "            continue\n",
    "        except sr.RequestError:\n",
    "            continue\n",
    "        except sr.WaitTimeoutError:\n",
    "            continue\n",
    "        if inp==\"stop listening\":\n",
    "            print('Goodbye!')\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84551323",
   "metadata": {},
   "source": [
    "Finally, let's use speech recognition to perform a web search.  To do that, all we need is to replace this line:\n",
    "\n",
    "```webbrowser.open(\"http://\" + inp)```\n",
    "\n",
    "...with this one:\n",
    "\n",
    "```webbrowser.open(\"http://google.com/search?q=\" + inp)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e103da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import webbrowser\n",
    "speech = sr.Recognizer()\n",
    "\n",
    "while True:\n",
    "    print('Python is listening...')\n",
    "    with sr.Microphone() as source:\n",
    "        speech.adjust_for_ambient_noise(source)\n",
    "        try:\n",
    "            audio = speech.listen(source)\n",
    "            inp = speech.recognize_google(audio)\n",
    "            print('You just said',inp,'.')\n",
    "            inp.replace('browser ', '')\n",
    "            webbrowser.open(\"http://google.com/search?q=\" + inp)\n",
    "        except sr.UnknownValueError:\n",
    "            continue\n",
    "        except sr.RequestError:\n",
    "            continue\n",
    "        except sr.WaitTimeoutError:\n",
    "            continue\n",
    "        if inp==\"stop listening\":\n",
    "            print('Goodbye!')\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba21aaa8",
   "metadata": {},
   "source": [
    "<a id=\"section_4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa81c535",
   "metadata": {},
   "source": [
    "## 4. Using speech_recognition from an audio file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d3c108",
   "metadata": {},
   "source": [
    "If you have an audio file, you can use the speech_recognition module to transcribe it.  For example, let's download the audio file we used in lecture 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5b6544",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, soundfile, IPython\n",
    "\n",
    "example_url = \"https://catalog.ldc.upenn.edu/desc/addenda/LDC93S1.wav\"\n",
    "webdata = urllib.request.urlopen(example_url).read()\n",
    "with open(\"webdata.wav\", \"wb\") as f:\n",
    "    f.write(webdata)\n",
    "    \n",
    "speech_wave, speech_rate = soundfile.read(\"webdata.wav\")\n",
    "IPython.display.Audio(data=speech_wave, rate=speech_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3069f3e",
   "metadata": {},
   "source": [
    "Now let's use speech_recognition to transcribe it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bc3623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "speech = sr.Recognizer()\n",
    "with sr.AudioFile(\"webdata.wav\") as source:\n",
    "    audio = speech.record(source)\n",
    "    inp = speech.recognize_google(audio)\n",
    "    print('The person in this audio file said:',inp,'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564707ab",
   "metadata": {},
   "source": [
    "<a id='homework'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6b32d4",
   "metadata": {},
   "source": [
    "## Homework for Week 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9eeaa5",
   "metadata": {},
   "source": [
    "Create a text file called `week9.py`.\n",
    "\n",
    "This file should `def` a function called `transcribe_wavefile`, with the following parameters:\n",
    "* Input: str = name of the input file\n",
    "* Return: str = recognized text  \n",
    "\n",
    "Here is a template that you can cut and paste, to get started:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c8138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "def transcribe_wavefile(filename):\n",
    "    '''\n",
    "    Use sr.Recognizer.AudioFile(filename) as the source,\n",
    "    recognize from that source,\n",
    "    and return the recognized text.\n",
    "    '''\n",
    "    raise \"You need to write this part!\"\n",
    "    return inp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9fb7cc",
   "metadata": {},
   "source": [
    "Test whether your code works by running the following block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ab6ecae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result2:\n",
      "{   'alternative': [   {   'confidence': 0.83203697,\n",
      "                           'transcript': 'she has a duck suit and Gracie '\n",
      "                                         'washer all year'},\n",
      "                       {   'transcript': 'she has a duck suit and greasy '\n",
      "                                         'washer all year'},\n",
      "                       {   'transcript': 'she has a duck suit and greasy water '\n",
      "                                         'all year'},\n",
      "                       {   'transcript': 'she has a duck suit and greasy wash '\n",
      "                                         'water all year'},\n",
      "                       {   'transcript': 'she has a duck suit and Gracie wash '\n",
      "                                         'water all year'}],\n",
      "    'final': True}\n",
      "The person in this audio file said: she has a duck suit and Gracie washer all year .\n",
      "she has a duck suit and Gracie washer all year\n"
     ]
    }
   ],
   "source": [
    "import week9, importlib\n",
    "importlib.reload(week9)\n",
    "\n",
    "inp = week9.transcribe_wavefile(\"webdata.wav\")\n",
    "print(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c769003c",
   "metadata": {},
   "source": [
    "When the block above is working, try uploading your text file `week9.py` to <a href=\"https://www.gradescope.com/\">Gradescope</a>.  The autograder checks the following things:\n",
    "\n",
    "1. Did you submit a text file called `week9.py`?\n",
    "1. Does your text file contains a method called `transcribe_wavefile`?\n",
    "1. Does `week9.transcribe_wavefile` return a string?\n",
    "1. Does `week9.transcribe_wavefile(\"webdata.wav\")` return the string `she has a duck suit and Gracie washer all year`?\n",
    "1. Does `week9.transcribe_wavefile` also work if applied to a secret audio file that is different from `webdata.wav`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ad19aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
